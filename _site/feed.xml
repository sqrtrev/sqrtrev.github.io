<?xml version="1.0" encoding="utf-8"?><?xml-stylesheet type="text/xml" href="/feed.xslt.xml"?><feed xmlns="http://www.w3.org/2005/Atom"><generator uri="http://jekyllrb.com" version="3.2.1">Jekyll</generator><link href="/feed.xml" rel="self" type="application/atom+xml" /><link href="/" rel="alternate" type="text/html" /><updated>2018-07-05T22:36:22+09:00</updated><id>/</id><title type="html">SQRTREV</title><subtitle>sqrtrev Github Page</subtitle><entry><title type="html">[ML] Tensorflow에서의 함수들 정리</title><link href="/Tensorflow-Functions/" rel="alternate" type="text/html" title="[ML] Tensorflow에서의 함수들 정리" /><published>2018-07-05T00:00:00+09:00</published><updated>2018-07-05T00:00:00+09:00</updated><id>/Tensorflow-Functions</id><content type="html" xml:base="/Tensorflow-Functions/">&lt;hr /&gt;

&lt;h2 id=&quot;tensorflow-주요-함수-정리&quot;&gt;Tensorflow 주요 함수 정리&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;본 포스팅은 Tensorflow API r1.8를 기준으로 작성되었습니다.&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;import tensorflow as tf&lt;/code&gt; 즉, tf에 tensorflow를 import했다는 가정에서 설명하겠습니다.&lt;/li&gt;
  &lt;li&gt;지속적으로 업데이트할 문서입니다. 첫 게시일은 18/07/05 입니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;ol&gt;
  &lt;li&gt;tf.Variable()&lt;br /&gt;
Tensorflow에서 변수를 생성할때 사용하는 함수.&lt;br /&gt;&lt;br /&gt;
공식 API에서 설명하는 함수는 아래와 같다.&lt;br /&gt;
&lt;img src=&quot;../images/4/3.PNG&quot; style=&quot;width:100%;&quot; /&gt;&lt;br /&gt;&lt;br /&gt;
“Variable()은 변수에 사용할 초기값을 요구합니다. 이 변수는 텐서의 어떤 타입이나 형태가 될수있습니다. 초기값은 변수의 형태와 타입을 정의합니다. 해당 함수를 사용한후, 변수의 타입과 형태는 고정됩니다. 이 값은 assign메서드를 사용해서 변경가능합니다.&lt;br /&gt;&lt;br /&gt;만약 나중에 변수의 형태를 바꾸고싶다면, &lt;code class=&quot;highlighter-rouge&quot;&gt;validate_shape=False&lt;/code&gt;와 &lt;code class=&quot;highlighter-rouge&quot;&gt;assign&lt;/code&gt; Op를 사용해야합니다.&lt;br /&gt;&lt;br /&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;Tensor&lt;/code&gt;나&lt;code class=&quot;highlighter-rouge&quot;&gt;Variable()&lt;/code&gt;로 생성된 것들은 그래프에서 다른 Op의 input으로 사용할 수 있습니다. 추가로, &lt;code class=&quot;highlighter-rouge&quot;&gt;Tensor&lt;/code&gt;class로 오버로드 되는 모든 Operator들은 변수로 넘겨집니다. 그래서 변수의 산술연산만으로 그래프에 노드를 추가할 수 있습니다.”&lt;br /&gt;&lt;br /&gt;
&lt;code class=&quot;highlighter-rouge&quot;&gt;w = tf.Variable(&amp;lt;initial-value&amp;gt;, name=&amp;lt;optional-name&amp;gt;&lt;/code&gt;&lt;br /&gt;
tf.Variable(초기값, name=&quot;optional name&quot;)&lt;br /&gt;
name은 말그대로 optional한 부분이기 때문에 굳이 적어주지 않아도 된다.&lt;br /&gt;
&lt;img src=&quot;../images/4/4.PNG&quot; style=&quot;width:100%;&quot; /&gt;&lt;br /&gt;
공식 API에서는 그래프를 실행할 때, 변수는 그 값을 사용하는 ops를 실행하기 전에 명시적으로 초기화해야 한다고 적혀있다. 그래서 위의 이미지와 같이 모든 변수를 초기화 할 그래프에 &lt;code class=&quot;highlighter-rouge&quot;&gt;initialize_all_variables()&lt;/code&gt;로 Op를 추가한다. 그후 그래프를 실행하고 Op를 실행한다.&lt;/li&gt;
&lt;/ol&gt;

&lt;h6 id=&quot;api문서-해석하고-찾아보니까-해석본이-이미-있었다&quot;&gt;API문서 해석하고 찾아보니까 해석본이 이미 있었다.&lt;/h6&gt;
&lt;p&gt;######—- 18.07.05 까지 내용 —-&lt;/p&gt;</content><summary type="html">Tensorflow의 API를 파헤쳐보자</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="/images/4/2.PNG" /></entry><entry><title type="html">[ML] Minimize cost</title><link href="/minimize-cost/" rel="alternate" type="text/html" title="[ML] Minimize cost" /><published>2018-07-04T00:00:00+09:00</published><updated>2018-07-04T00:00:00+09:00</updated><id>/minimize cost</id><content type="html" xml:base="/minimize-cost/">&lt;h2 id=&quot;how-to-minimize-the-cost-of-linear-regression&quot;&gt;How to minimize the cost of Linear Regression&lt;/h2&gt;
&lt;p&gt;Linear Regression의 Hypothesis를 &lt;code class=&quot;highlighter-rouge&quot;&gt;H(x) = Wx&lt;/code&gt;라고 단순하게 표현한다고 하자, W를 x축, Cost를 Y축에 나타낸다면 아래와 같은 그래프가 만들어지게 된다.&lt;br /&gt;
&lt;img src=&quot;../images/3/1.PNG&quot; style=&quot;width:100%;&quot; alt=&quot;그림1&quot; /&gt;&lt;br /&gt;
우리가 Cost를 최소화 시키기 위해서 Gradient Descent Algorithm을 사용할 것이며, 여기에는 미분이 사용된다.&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;특정 좌표에서 시작한다&lt;br /&gt;
-Weight 값을 계속 변화시키며, bias를 아주 약간 다르게하여 cost(W,b)를 감소시킨다.&lt;/li&gt;
  &lt;li&gt;파라미터의 값을 변화시킬 때 마다, cost(W,b)를 가능한 가장 많이 줄여주는 순간기울기를 선택한다.&lt;/li&gt;
  &lt;li&gt;최솟값으로 모일때까지 반복한다.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;img src=&quot;../images/3/2.PNG&quot; style=&quot;width:100%;&quot; /&gt;&lt;br /&gt;
위 이미지가 미분한 결과이다. 이미지에서 알파(a)는 Learning Rate를 의미하며, 나중에 문서에서 설명하도록 하겠다.&lt;br /&gt;&lt;br /&gt;그림1을 보면 최적의 W는 1이다. 만약 우리가 위 공식을 이용해서 최적의 1의 값을 찾는다고 하면, W가 4.0에서 시작했다면 W의 값이 왼쪽(감소)으로 가야한다. 이 과정의 반복을 통해 최적의 W를 찾아낼 수 있는 것이다!&lt;br /&gt;&lt;br /&gt;이처럼 W를 다시 찾는다고 하면 어느 방향으로 이동하는지가 중요한 관건이지만, Tensorflow에서는 함수가 알아서 편리하게 계산해준다 XD.&lt;br /&gt;
여튼 요약하자면 공식은 아래와 같이 정리된다&lt;br /&gt;
&lt;code class=&quot;highlighter-rouge&quot;&gt;W = W - learning_rate * 순간기울기&lt;/code&gt;&lt;br /&gt;
추가로 Convex Function도 확인하고 사용해줘야 한다.&lt;br /&gt;
&lt;img src=&quot;../images/3/3.PNG&quot; style=&quot;width:100%;&quot; /&gt;&lt;br /&gt;
이미지 출처: http://www.holehouse.org/mlclass
&lt;br /&gt;
위 이미지가 Convex Function이라는 것인데, X축은 W, Y축은 b, Z축은 cost를 나타내는 것이다. 위에서 보면 두개의 다른 좌표에서 시작하여 Gradient Descent Algorithm을 실행 했지만, 다른 좌표에 도착한게 된다. 따라서 정확한 값을 얻지 못한다는 말이다.&lt;br /&gt;
&lt;img src=&quot;../images/3/4.PNG&quot; style=&quot;width:100%;&quot; /&gt;&lt;br /&gt;
이미지 출처: http://www.holehouse.org/mlclass&lt;br /&gt;
위에서 보이는 그림이 바람직한 Convex Function의 그림이다.&lt;/p&gt;</content><summary type="html">Linear Regression의 Cost 최소화 알고리즘 원리</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="/images/3/2.PNG" /></entry><entry><title type="html">[ML] Basic Terms and Notions</title><link href="/Linear-Regression/" rel="alternate" type="text/html" title="[ML] Basic Terms and Notions" /><published>2018-07-03T00:00:00+09:00</published><updated>2018-07-03T00:00:00+09:00</updated><id>/Linear Regression</id><content type="html" xml:base="/Linear-Regression/">&lt;hr /&gt;

&lt;h2 id=&quot;supervised-or-unsupervised&quot;&gt;Supervised Or Unsupervised&lt;/h2&gt;
&lt;p&gt;ML(Machine Learning)에는 두가지의 학습방법이 있다.&lt;br /&gt;&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;Supervised Learning&lt;br /&gt;&lt;/li&gt;
  &lt;li&gt;Unsupervised Learning&lt;br /&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Supervised Learning은 고양이나 강아지와 같이 Label을 붙일수 있는 사진같은 것들을 학습시키는 것이다.&lt;br /&gt;
반면, Label을 붙여줄 수 없는 것들(뉴스, 단어 등등)의 경우 데이터를 보고 스스로 유사한 것들끼리 분류하게 학습하는 것을 Unsupervised Learning이라 한다.&lt;br /&gt;
Supervised Learning의 예시는 아래와 같다.&lt;br /&gt;
● Image labeling(Label된 이미지들을 학습시켜 구분시키는 것)&lt;br /&gt;
● Email spam filter(스팸으로 구분된 메일들을 학습시켜 스팸을 구분하는것)&lt;br /&gt;
● Predicting exam score(여태까지의 시험점수와 공부에 사용한 시간을 학습시켜 점수를 예측시키는 것)
&lt;br /&gt;&lt;/p&gt;
&lt;h2 id=&quot;dataset&quot;&gt;Dataset&lt;/h2&gt;
&lt;p&gt;Dataset은 데이터 X = {x1,x2,..,xn}과 Y = {y1,y2,..,yn}을 말하는 것으로, Dataset을 이용해 ML을 통해 Y에 최대한 Prediction을 가깝게 해주는데 사용한다. 쉽게 정리하자면, 학습시킬때 사용할 input과 output정도로 생각해주면 편하다.
&lt;br /&gt;&lt;/p&gt;
&lt;h2 id=&quot;types-of-supervised-learning&quot;&gt;Types of supervised learning&lt;/h2&gt;
&lt;p&gt;● 공부 시간에 따른 시험점수 예측(0~100점)&lt;br /&gt;
= Regression&lt;br /&gt;
● 공부 시간에 따른 합격/불합격 여부&lt;br /&gt;
= Binary classification&lt;br /&gt;
● 공부 시간에 따른 A,B…F 학점 매기기&lt;br /&gt;
= Multi-label classification&lt;br /&gt;
● 이메일에 들어가있는 단어들에 대해서 스팸 여부 확인&lt;br /&gt;
= Naive Bayes Classification (Thanks To hong9802)&lt;br /&gt;
*여담 - Naive Bayes Classification도 추가해 달라는 홍현이의 말을 듣고 자료를 찾아보았다. Naive Bayes Classification는 베이즈의 정리를 이용하여, 분류하고자 하는 대상의 각 분류별 확률을 측정하여 확률이 큰 쪽으로 분류하는것이었다. 자세한 자료는 아래 링크를 참고하자.&lt;br /&gt;
http://bcho.tistory.com/1010
&lt;br /&gt;&lt;/p&gt;
&lt;h2 id=&quot;hypothesis---cost-function&quot;&gt;Hypothesis  &amp;amp; Cost function&lt;/h2&gt;
&lt;p&gt;A.I를 공부하기에 앞서 가설(Hypothesis)과 비용 함수(Cost Function)에 대한 이해가 필요하다.&lt;br /&gt;
Machine Learning은 주어진 데이터 X = {x1,x2,x3,..,xn}와 데이터에 대응하는 실제 현상 Y = {y1,y2,..,yn}에 대한 관계함수 f를 찾는 과정이다. 정확한 함수 f를 찾기 위해 Maching Learning 알고리즘들은 데이터에 대한 가정을 하고, 그 가정에 따라 주어진 데이터를 최대한 잘 설명할 수 있는 함수 &lt;code class=&quot;highlighter-rouge&quot;&gt;f′&lt;/code&gt;을 찾고, 이 &lt;code class=&quot;highlighter-rouge&quot;&gt;f′&lt;/code&gt;을 Hypothesis라고 한다.&lt;br /&gt;
(Hypothesis에 대한 설명 출처: http://sanghyukchun.github.io/57/)
&lt;br /&gt;&lt;br /&gt;
Machine Learning에서 학습을 진행하기 위해서는 모델의 정확도를 측정하고, 예측 값(측정 값)과 실제 값 차이의 평균을 구해야 한다. 이것을 구하는 것이 Cost Function(Loss Function)이다.
&lt;br /&gt;
Hypothesis를 함수 H(x)라고 하면, Linear Regression에서의 가장 기초적인 H(x)는 &lt;code class=&quot;highlighter-rouge&quot;&gt;H(x) = Wx + b&lt;/code&gt;가 된다.&lt;br /&gt;
Cost Function은 Loss Function이라고도 부르며, 실제 값과 Prediction(예측 값)과의 차이를 제곱하여 평균을 구한것이다(아래 이미지 참고).&lt;br /&gt;
&lt;img src=&quot;../images/2/1.PNG&quot; style=&quot;width:100%;&quot; /&gt;&lt;br /&gt;
위 사진에서 m = 데이터 갯수를 나타낸다.&lt;br /&gt;
함수 H(x)와 Cost함수를 합치면 아래와 같은 식이 나오게된다.&lt;br /&gt;
&lt;img src=&quot;../images/2/2.PNG&quot; style=&quot;width:100%&quot; /&gt;&lt;br /&gt;
즉, Linear Regression에서의 ML의 학습이란,  &lt;code class=&quot;highlighter-rouge&quot;&gt;cost(W,b)&lt;/code&gt;의 값을 가장 작게 만드는 W와 b를 찾는것이다.&lt;/p&gt;</content><summary type="html">기본적인 Machine Learning의 용어 및 개념</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="/images/2/2.PNG" /></entry><entry><title type="html">[Reversing.kr] Easy Crack</title><link href="/Reversing.Kr-Easy-Crack-me/" rel="alternate" type="text/html" title="[Reversing.kr] Easy Crack" /><published>2018-07-02T00:00:00+09:00</published><updated>2018-07-02T00:00:00+09:00</updated><id>/[Reversing.Kr] Easy Crack me</id><content type="html" xml:base="/Reversing.Kr-Easy-Crack-me/">&lt;hr /&gt;

&lt;p&gt;사실 reversing.kr은 KH2RS라는 닉네임으로 여러문제를 풀었던 적이 있다. &lt;br /&gt;하지만 블로그를 새롭게 만들면서 다시 풀어보자는 생각으로 sqrtrev라는 닉네임으로 다시 계정을 만들었다.
&lt;br /&gt;&lt;br /&gt;
&lt;img src=&quot;../images/1/post1_ (1).png&quot; /&gt;
&lt;br /&gt;Easy_CrackMe.exe 실행화면
&lt;br /&gt;&lt;br /&gt;
프로그램을 실행해보면 무언가 값을 입력 가능하고, 확인 버튼을 누르면 Incorrect Password라는 문구를 띄운다.&lt;br /&gt;아마도 이 문제의 정답은 저 패스워드를 구하는게 아닐까?&lt;br /&gt;바로 IDA로 열어보자.&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../images/1/post1_ (2).png&quot; style=&quot;width:100%;&quot; /&gt;
&lt;br /&gt;
sub_401080을 열어보면 아래와 같이 변수가 선언되어있다.
&lt;br /&gt;&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;int result;
CHAR String; // [sp+4h]
char v3; // [sp+5h]
char v4; // [sp+6h]
char v5; // [sp+8h]
__int16 v6;
char v7;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;p&gt;쉽게 말해서 메모리를 표현하자면 아래와 같다.&lt;br /&gt;
&lt;code class=&quot;highlighter-rouge&quot;&gt;string | v3 | v4 | v5&lt;/code&gt;&lt;br /&gt;&lt;br /&gt;
다음은 16번째 줄의 if문을 보자&lt;br /&gt;&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;if ( v3 == 97 &amp;amp;&amp;amp; !strncmp(&amp;amp;v4, a5y, 2u) &amp;amp;&amp;amp; !strcmp(&amp;amp;v5, aR3versing) &amp;amp;&amp;amp; String == 69 )
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;p&gt;v3가 97(ASCII로 a), v4가 변수 a5y, v5가 변수 aR3versing, String이 69(ASCII로 E)라는 조건을 가지고 있는 if문이다.
&lt;br /&gt;
그러면 a5y와 aR3versing에는 어떤 값이 저장되어있는지 확인해보자.&lt;br /&gt;&lt;br /&gt;
&lt;img src=&quot;../images/1/post1_ (3).PNG&quot; style=&quot;width:100%;&quot; /&gt;
aR3versing에는 R3versing이라는 값이, a5y에는 5y라는 값이 저장되어있다.&lt;br /&gt;
위 내용을 기반으로 값들을 조합하면 Password가 나오게된다.&lt;br /&gt;
&lt;img src=&quot;../images/1/post1_ (4).png&quot; /&gt;&lt;br /&gt;
Clear!
&lt;br /&gt;
키값은 따로 공유하지 않도록 하겠다.&lt;/p&gt;</content><summary type="html">Reversing.kr 1번</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="/images/1/post1_ (2).png" /></entry></feed>
